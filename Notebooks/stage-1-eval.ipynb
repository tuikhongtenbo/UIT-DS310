{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13811466,"sourceType":"datasetVersion","datasetId":8794412},{"sourceId":13960552,"sourceType":"datasetVersion","datasetId":8899104},{"sourceId":13960658,"sourceType":"datasetVersion","datasetId":8899185},{"sourceId":13989482,"sourceType":"datasetVersion","datasetId":8916581}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"01a809d6","cell_type":"markdown","source":"# Evaluation Stage 1: Candidate Retrieval Performance\n\n## Mục tiêu:\n- Evaluate retrieval performance trên tập train\n- Metrics: P@100, R@100\n- 3 methods: BM25, Dense retrieval, Hybrid search (Ensemble)\n- So sánh kết quả giữa các methods","metadata":{}},{"id":"2839119f-9735-4f28-8c4c-bceee0f1b3a4","cell_type":"code","source":"!pip install chromadb sentence_transformers pyvi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:19:16.380295Z","iopub.execute_input":"2025-12-04T15:19:16.380485Z","iopub.status.idle":"2025-12-04T15:20:46.020229Z","shell.execute_reply.started":"2025-12-04T15:19:16.380468Z","shell.execute_reply":"2025-12-04T15:20:46.019527Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting chromadb\n  Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\nRequirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nCollecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.12.4)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\nRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.15.0)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.37.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.3)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.2.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.53.3)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.3.0)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.10.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nCollecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (6.33.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-semantic-conventions==0.60b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.11.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\nCollecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.4)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.39.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.39.0-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.39.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl (219 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\nDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\nDownloading httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.6/456.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=afd65c9d5045fe028a9ab8eabff9a94a0ddc70f79d0fe6acacfddb70cc84d0a1\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, durationpy, uvloop, urllib3, python-crfsuite, pybase64, opentelemetry-proto, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mmh3, humanfriendly, httptools, cachetools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, posthog, opentelemetry-semantic-conventions, nvidia-cusolver-cu12, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, sklearn-crfsuite, onnxruntime, pyvi, chromadb\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.5.0\n    Uninstalling urllib3-2.5.0:\n      Successfully uninstalled urllib3-2.5.0\n  Attempting uninstall: opentelemetry-proto\n    Found existing installation: opentelemetry-proto 1.37.0\n    Uninstalling opentelemetry-proto-1.37.0:\n      Successfully uninstalled opentelemetry-proto-1.37.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.1\n    Uninstalling cachetools-6.2.1:\n      Successfully uninstalled cachetools-6.2.1\n  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.37.0\n    Uninstalling opentelemetry-api-1.37.0:\n      Successfully uninstalled opentelemetry-api-1.37.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.37.0\n    Uninstalling opentelemetry-sdk-1.37.0:\n      Successfully uninstalled opentelemetry-sdk-1.37.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-adk 1.18.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\ngoogle-adk 1.18.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\nopentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 cachetools-5.5.2 chromadb-1.3.5 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.23.2 opentelemetry-api-1.39.0 opentelemetry-exporter-otlp-proto-common-1.39.0 opentelemetry-exporter-otlp-proto-grpc-1.39.0 opentelemetry-proto-1.39.0 opentelemetry-sdk-1.39.0 opentelemetry-semantic-conventions-0.60b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n","output_type":"stream"}],"execution_count":1},{"id":"9e0d19cf","cell_type":"code","source":"import os\nimport json\nimport pickle\nimport numpy as np\nfrom typing import List, Dict, Tuple, Any\nfrom tqdm import tqdm\nimport torch\nfrom collections import defaultdict\nimport shutil\n\n# ChromaDB\nimport chromadb\nfrom chromadb.config import Settings\n\n# Sentence Transformers\nfrom sentence_transformers import SentenceTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:20:46.021864Z","iopub.execute_input":"2025-12-04T15:20:46.022172Z","iopub.status.idle":"2025-12-04T15:21:28.355996Z","shell.execute_reply.started":"2025-12-04T15:20:46.022138Z","shell.execute_reply":"2025-12-04T15:21:28.355450Z"}},"outputs":[{"name":"stderr","text":"2025-12-04 15:21:07.168470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764861667.365133      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764861667.420482      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"id":"58e43cd0","cell_type":"markdown","source":"## Configuration","metadata":{}},{"id":"0d801ec8","cell_type":"code","source":"# Paths (Kaggle)\nTRAIN_FILE = \"/kaggle/input/vlqa-dataset/train.json\"\nBM25_INDEX_PATH = \"/kaggle/input/bm25-index/bm25_index.pkl\"\nCHROMA_DB_PATH = \"/kaggle/input/chroma-db-retriever/chroma_db_retriever\"\nCOLLECTION_NAME = \"retriever_legal_articles\"\n\n# Embedding model\nEMBEDDING_MODEL = \"AITeamVN/Vietnamese_Embedding\"\n\n# Evaluation parameters\nTOP_K = 300  # P@100, R@100\nMAX_SAMPLES = None  \n\n# Ensemble weights\nBM25_WEIGHT = 0.3\nDENSE_WEIGHT = 0.7\n\n# Device\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {DEVICE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:21:28.356602Z","iopub.execute_input":"2025-12-04T15:21:28.357175Z","iopub.status.idle":"2025-12-04T15:21:28.361848Z","shell.execute_reply.started":"2025-12-04T15:21:28.357155Z","shell.execute_reply":"2025-12-04T15:21:28.360942Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"id":"6a8d1cfd","cell_type":"markdown","source":"## Helper Classes and Functions","metadata":{}},{"id":"d76ab9f9","cell_type":"code","source":"# ==========================================\n# ChromaIndex Class\n# ==========================================\nclass ChromaIndex:\n    \"\"\"ChromaDB index for storing and querying embeddings\"\"\"\n    \n    def __init__(self, persist_directory: str, collection_name: str = \"legal_articles_chunks\"):\n        \"\"\"Initialize ChromaDB index.\"\"\"\n        actual_path = self._resolve_db_path(persist_directory)\n        \n        self.persist_directory = actual_path\n        self.collection_name = collection_name\n        print(f\"Initialize ChromaDB at {actual_path}\")\n        \n        self.client = chromadb.PersistentClient(path=actual_path)\n        self.collection = self.client.get_or_create_collection(\n            name=collection_name,\n            metadata={\"hnsw:space\": \"cosine\"}\n        )\n        print(f\"Collection: {collection_name} is ready. Current count: {self.collection.count()}\")\n    \n    def _resolve_db_path(self, path: str) -> str:\n        \"\"\"Resolve database path, copying from read-only location if needed.\"\"\"\n        if '/kaggle/input/' in path:\n            working_path = path.replace('/kaggle/input/', '/kaggle/working/')\n            \n            if not os.path.exists(working_path):\n                print(f\"Copying ChromaDB from read-only to writable location...\")\n                print(f\"  From: {path}\")\n                print(f\"  To:   {working_path}\")\n                try:\n                    os.makedirs(os.path.dirname(working_path), exist_ok=True)\n                    try:\n                        shutil.copytree(path, working_path, dirs_exist_ok=True)\n                    except TypeError:\n                        if os.path.exists(working_path):\n                            shutil.rmtree(working_path)\n                        shutil.copytree(path, working_path)\n                    print(\"Database copied successfully\")\n                except Exception as e:\n                    print(f\"Failed to copy database: {e}\")\n                    raise RuntimeError(f\"Cannot copy ChromaDB from {path} to {working_path}: {e}\")\n            else:\n                print(f\"Using existing copy at: {working_path}\")\n            \n            return working_path\n        \n        return path\n\n# ==========================================\n# WeightedEnsemble Class\n# ==========================================\nclass WeightedEnsemble:\n    \"\"\"Pure Logic for Weighted Ensemble Fusion.\"\"\"\n    \n    def __init__(self, weights: tuple = (0.5, 0.5)):\n        self.weights = weights\n    \n    def _normalize_scores(self, scores: Dict[str, float]) -> Dict[str, float]:\n        if not scores: return {}\n        values = list(scores.values())\n        min_score = min(values)\n        max_score = max(values)\n        if max_score == min_score: return {k: 1.0 for k in scores}\n        return {k: (v - min_score) / (max_score - min_score) for k, v in scores.items()}\n    \n    def rank(self, bm25_scores: Dict[str, float], dense_scores: Dict[str, float], top_k: int = 100) -> List[Tuple[str, float]]:\n        w1, w2 = self.weights\n        norm_bm25 = self._normalize_scores(bm25_scores)\n        norm_dense = self._normalize_scores(dense_scores)\n        all_ids = set(norm_bm25.keys()) | set(norm_dense.keys())\n        \n        final_scores = {}\n        for doc_id in all_ids:\n            s1 = norm_bm25.get(doc_id, 0.0)\n            s2 = norm_dense.get(doc_id, 0.0)\n            final_scores[doc_id] = (w1 * s1) + (w2 * s2)\n        \n        sorted_docs = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n        return sorted_docs[:top_k]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:21:28.362895Z","iopub.execute_input":"2025-12-04T15:21:28.363267Z","iopub.status.idle":"2025-12-04T15:21:28.391469Z","shell.execute_reply.started":"2025-12-04T15:21:28.363241Z","shell.execute_reply":"2025-12-04T15:21:28.390787Z"}},"outputs":[],"execution_count":4},{"id":"04f80aec","cell_type":"code","source":"def calculate_precision_at_k(predicted_ids: List[str], relevant_ids: List[str], k: int = 100) -> float:\n    \"\"\"\n    Calculate Precision@k\n    \n    Args:\n        predicted_ids: List of predicted article IDs (ranked)\n        relevant_ids: List of relevant article IDs\n        k: Top-k to consider\n    \n    Returns:\n        Precision@k score\n    \"\"\"\n    predicted_ids = [str(pid) for pid in predicted_ids]\n    relevant_set = set(str(rid) for rid in relevant_ids)\n    \n    if len(predicted_ids) == 0:\n        return 0.0\n    \n    # Count relevant items in top-k\n    relevant_in_topk = sum(1 for doc_id in predicted_ids[:k] if doc_id in relevant_set)\n    \n    # Precision = relevant_retrieved / total_retrieved\n    precision = relevant_in_topk / min(k, len(predicted_ids))\n    return precision\n\ndef calculate_recall_at_k(predicted_ids: List[str], relevant_ids: List[str], k: int = 100) -> float:\n    \"\"\"\n    Calculate Recall@k\n    \n    Args:\n        predicted_ids: List of predicted article IDs (ranked)\n        relevant_ids: List of relevant article IDs\n        k: Top-k to consider\n    \n    Returns:\n        Recall@k score\n    \"\"\"\n    predicted_ids = [str(pid) for pid in predicted_ids]\n    relevant_set = set(str(rid) for rid in relevant_ids)\n    \n    if len(relevant_set) == 0:\n        return 0.0\n    \n    # Count relevant items in top-k\n    relevant_in_topk = sum(1 for doc_id in predicted_ids[:k] if doc_id in relevant_set)\n    \n    # Recall = relevant_retrieved / total_relevant\n    recall = relevant_in_topk / len(relevant_set)\n    return recall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:21:28.392235Z","iopub.execute_input":"2025-12-04T15:21:28.392555Z","iopub.status.idle":"2025-12-04T15:21:28.412776Z","shell.execute_reply.started":"2025-12-04T15:21:28.392531Z","shell.execute_reply":"2025-12-04T15:21:28.412166Z"}},"outputs":[],"execution_count":5},{"id":"4d8f672b","cell_type":"code","source":"# Load train data\nprint(f\"Loading train data from {TRAIN_FILE}...\")\nwith open(TRAIN_FILE, 'r', encoding='utf-8') as f:\n    train_data = json.load(f)\n\nif MAX_SAMPLES:\n    train_data = train_data[:MAX_SAMPLES]\n    print(f\"Limited to {MAX_SAMPLES} samples\")\n\n# Load BM25 index\nprint(f\"\\nLoading BM25 index from {BM25_INDEX_PATH}...\")\nwith open(BM25_INDEX_PATH, 'rb') as f:\n    bm25_data = pickle.load(f)\n\n# Load ChromaDB\nprint(f\"\\nLoading ChromaDB from {CHROMA_DB_PATH}...\")\nchroma_index = ChromaIndex(\n    persist_directory=CHROMA_DB_PATH,\n    collection_name=COLLECTION_NAME\n)\n\n# Load embedding model\nprint(f\"\\nLoading embedding model: {EMBEDDING_MODEL}...\")\nembedder_model = SentenceTransformer(EMBEDDING_MODEL, device=DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:21:28.413509Z","iopub.execute_input":"2025-12-04T15:21:28.413727Z","iopub.status.idle":"2025-12-04T15:22:04.881393Z","shell.execute_reply.started":"2025-12-04T15:21:28.413711Z","shell.execute_reply":"2025-12-04T15:22:04.880563Z"}},"outputs":[{"name":"stdout","text":"Loading train data from /kaggle/input/vlqa-dataset/train.json...\n\nLoading BM25 index from /kaggle/input/bm25-index/bm25_index.pkl...\n\nLoading ChromaDB from /kaggle/input/chroma-db-retriever/chroma_db_retriever...\nCopying ChromaDB from read-only to writable location...\n  From: /kaggle/input/chroma-db-retriever/chroma_db_retriever\n  To:   /kaggle/working/chroma-db-retriever/chroma_db_retriever\nDatabase copied successfully\nInitialize ChromaDB at /kaggle/working/chroma-db-retriever/chroma_db_retriever\nCollection: retriever_legal_articles is ready. Current count: 74352\n\nLoading embedding model: AITeamVN/Vietnamese_Embedding...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47f8dd0e54a4295ab96df5aa16a6014"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21d5386dc6a04ce190070e52dbefd6d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b2697ce2be3470cbd87684036eb5302"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0adda7c6105940b1b0b9bbc4a66f8dc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/708 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c19d7413abb4642ae1d06eba7160b98"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44242004ca6542ada80f9094e9608cf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec2aa7c1229248e6bca7ffbc3c47b921"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e13d210794d4157ad67be5b58672856"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e19ba6b41ab4205b84b1b59a81af945"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6b778991b84c6198c4ec6895205a27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b650f8b27cd4afdac77bad722ec0cb5"}},"metadata":{}}],"execution_count":6},{"id":"4fd7fbcc","cell_type":"markdown","source":"## Initialize Retrievers","metadata":{}},{"id":"6e529a32","cell_type":"code","source":"# BM25 Retriever \n# BM25 Retriever (FIXED: Aggregation by AID + Better Tokenizer)\nclass BM25Retriever:\n    def __init__(self, bm25_data, chroma_index=None):\n        \"\"\"\n        Initialize BM25 Retriever.\n        \n        Args:\n            bm25_data: Loaded pickle data from bm25_index.pkl\n            chroma_index: ChromaIndex instance (optional, for mapping chunk_id -> aid)\n        \"\"\"\n        # Load data from pickle (structure from bm25_retriever.save())\n        self.corpus_size = bm25_data['corpus_size']\n        self.avgdl = bm25_data['avgdl']\n        self.doc_lengths = bm25_data['doc_lengths']\n        self.doc_ids = bm25_data['doc_ids']\n        self.index_to_id = bm25_data.get('index_to_id', {})\n        self.inverted_index = bm25_data['inverted_index']\n        self.idf = bm25_data['idf']\n        self.k1 = 1.5\n        self.b = 0.75\n        \n        # ChromaDB for mapping chunk_id -> aid (if needed)\n        self.chroma_index = chroma_index\n        \n        # Cache for doc_id -> aid mapping (to avoid repeated queries)\n        self._doc_id_to_aid_cache = {}\n        \n        # FIX TOKENIZER: Try pyvi for Vietnamese, fallback to simple split\n        try:\n            from pyvi import ViTokenizer\n            self.tokenizer = lambda x: ViTokenizer.tokenize(x).split()\n            print(\"✅ BM25: Using Pyvi tokenizer for Vietnamese\")\n        except ImportError:\n            try:\n                import underthesea\n                self.tokenizer = lambda x: underthesea.word_tokenize(x.lower())\n                print(\"✅ BM25: Using Underthesea tokenizer for Vietnamese\")\n            except ImportError:\n                # Fallback: simple split (worse for Vietnamese)\n                print(\"⚠️ BM25: Using simple split (install 'pyvi' or 'underthesea' for better Vietnamese tokenization)\")\n                self.tokenizer = lambda x: x.lower().split()\n    \n    def _get_aid_from_doc_id(self, doc_id: str) -> str:\n        \"\"\"\n        Get article ID (aid) from document ID (chunk_id).\n        If doc_id is already aid, return it. Otherwise, query ChromaDB.\n        \"\"\"\n        if doc_id in self._doc_id_to_aid_cache:\n            return self._doc_id_to_aid_cache[doc_id]\n        \n        # Try 1: Assume doc_id is already aid (if index was built with aid as id)\n        # This is the case if build_bm25_index.py used \"aid\" as id\n        aid = doc_id\n        \n        # Try 2: Query ChromaDB to get aid from metadata\n        if self.chroma_index:\n            try:\n                # Query by doc_id (chunk_id)\n                results = self.chroma_index.collection.get(\n                    ids=[doc_id],\n                    include=[\"metadatas\"]\n                )\n                if results and results.get('metadatas') and len(results['metadatas']) > 0:\n                    metadata = results['metadatas'][0]\n                    if metadata and 'aid' in metadata:\n                        aid = str(metadata['aid'])\n            except Exception as e:\n                # If query fails, assume doc_id is aid\n                pass\n        \n        # Cache the result\n        self._doc_id_to_aid_cache[doc_id] = aid\n        return aid\n    \n    def retrieve(self, query: str, top_k: int = 100) -> List[Tuple[str, float]]:\n        \"\"\"\n        Retrieve top-k documents using BM25 with AGGREGATION BY AID.\n        Similar to DenseRetriever, groups chunks by article and keeps max score.\n        \"\"\"\n        if self.corpus_size == 0:\n            return []\n        \n        # Tokenize query\n        query_tokens = self.tokenizer(query)\n        scores = defaultdict(float)\n        \n        # Calculate BM25 scores for all chunks\n        for token in query_tokens:\n            if token not in self.inverted_index:\n                continue\n            \n            idf_score = self.idf[token]\n            \n            for doc_idx, term_freq in self.inverted_index[token].items():\n                doc_len = self.doc_lengths[doc_idx]\n                \n                numerator = term_freq * (self.k1 + 1)\n                denominator = term_freq + self.k1 * (1 - self.b + self.b * (doc_len / self.avgdl))\n                score = idf_score * (numerator / denominator)\n                \n                scores[doc_idx] += score\n        \n        # FIX: AGGREGATION BY ARTICLE ID (AID)\n        # Group scores by aid (similar to DenseRetriever)\n        article_scores = defaultdict(float)\n        \n        for doc_idx, score in scores.items():\n            doc_id = str(self.index_to_id.get(doc_idx, doc_idx))\n            # Get aid from doc_id (chunk_id)\n            aid = self._get_aid_from_doc_id(doc_id)\n            \n            # Keep MAX score for each article (if multiple chunks)\n            if score > article_scores[aid]:\n                article_scores[aid] = score\n        \n        # Sort by score and return top-k\n        sorted_scores = sorted(article_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n        \n        return [(str(aid), float(score)) for aid, score in sorted_scores]\n\n# Dense Retriever\nclass DenseRetriever:\n    def __init__(self, chroma_index, embedder_model):\n        self.chroma_index = chroma_index\n        self.embedder_model = embedder_model\n    \n    def retrieve(self, query: str, top_k: int = 100) -> List[Tuple[str, float]]:\n        \"\"\"Retrieve top-k documents using Dense retrieval.\"\"\"\n        # Encode query\n        query_embedding = self.embedder_model.encode(query, convert_to_numpy=True, normalize_embeddings=True)\n        if len(query_embedding.shape) > 1:\n            query_vec = query_embedding[0].tolist()\n        else:\n            query_vec = query_embedding.tolist()\n        \n        # Query ChromaDB\n        results = self.chroma_index.collection.query(\n            query_embeddings=[query_vec],\n            n_results=top_k,\n            include=[\"metadatas\", \"distances\"]\n        )\n        \n        if not results or not results.get('ids') or not results['ids'][0]:\n            return []\n        \n        ids = results['ids'][0]\n        distances = results['distances'][0]\n        metadatas = results['metadatas'][0] if results.get('metadatas') else []\n        \n        # Deduplicate by aid\n        retrieved_items = {}\n        for i, doc_id in enumerate(ids):\n            dist = distances[i]\n            score = 1.0 - dist\n            score = max(0.0, min(1.0, score))\n            \n            aid = None\n            if metadatas and i < len(metadatas) and metadatas[i]:\n                aid = str(metadatas[i].get('aid', doc_id))\n            else:\n                aid = str(doc_id)\n            \n            if aid not in retrieved_items or score > retrieved_items[aid][1]:\n                retrieved_items[aid] = (aid, score)\n        \n        return list(retrieved_items.values())\n\n# Ensemble Retriever (FIXED: Increase search_k for better overlap)\nclass EnsembleRetriever:\n    def __init__(self, bm25_retriever, dense_retriever, weights: tuple = (0.5, 0.5)):\n        self.bm25 = bm25_retriever\n        self.dense = dense_retriever\n        self.fusion = WeightedEnsemble(weights=weights)\n    \n    def retrieve(self, query: str, top_k: int = 100) -> List[Tuple[str, float]]:\n        \"\"\"\n        Retrieve using ensemble (hybrid search).\n        FIX: Retrieve more candidates (2x-3x) to increase overlap between BM25 and Dense.\n        \"\"\"\n        # FIX: Retrieve more candidates to increase intersection\n        # This helps WeightedEnsemble find common documents between BM25 and Dense\n        search_k = max(top_k * 2, 100)  # At least 2x top_k, minimum 100\n        \n        # Get results from both retrievers\n        try:\n            bm25_results = self.bm25.retrieve(query, top_k=search_k)\n        except Exception as e:\n            print(f\"BM25 Retrieval failed: {e}\")\n            bm25_results = []\n        \n        try:\n            dense_results = self.dense.retrieve(query, top_k=search_k)\n        except Exception as e:\n            print(f\"Dense Retrieval failed: {e}\")\n            dense_results = []\n        \n        # Convert to dict\n        bm25_scores = dict(bm25_results)\n        dense_scores = dict(dense_results)\n        \n        # Combine using weighted ensemble\n        return self.fusion.rank(bm25_scores, dense_scores, top_k=top_k)\n\n# Initialize retrievers\nprint(\"Initializing retrievers...\")\n# FIX: Pass chroma_index to BM25Retriever for aid mapping\nbm25_retriever = BM25Retriever(bm25_data, chroma_index=chroma_index)\ndense_retriever = DenseRetriever(chroma_index, embedder_model)\nensemble_retriever = EnsembleRetriever(\n    bm25_retriever, \n    dense_retriever, \n    weights=(BM25_WEIGHT, DENSE_WEIGHT)\n)\nprint(\"✅ Retrievers initialized with fixes:\")\nprint(\"   - BM25: Aggregation by AID + Better tokenizer\")\nprint(\"   - Ensemble: Increased search_k for better overlap\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:22:04.883816Z","iopub.execute_input":"2025-12-04T15:22:04.884039Z","iopub.status.idle":"2025-12-04T15:22:04.958965Z","shell.execute_reply.started":"2025-12-04T15:22:04.884021Z","shell.execute_reply":"2025-12-04T15:22:04.958366Z"}},"outputs":[{"name":"stdout","text":"Initializing retrievers...\n✅ BM25: Using Pyvi tokenizer for Vietnamese\n✅ Retrievers initialized with fixes:\n   - BM25: Aggregation by AID + Better tokenizer\n   - Ensemble: Increased search_k for better overlap\n","output_type":"stream"}],"execution_count":7},{"id":"790b31fa","cell_type":"markdown","source":"## Run Evaluation","metadata":{}},{"id":"1a6e3762","cell_type":"code","source":"# Storage for results\nresults = {\n    'bm25': {'precision': [], 'recall': []},\n    'dense': {'precision': [], 'recall': []},\n    'ensemble': {'precision': [], 'recall': []}\n}\n\nprint(f\"Evaluating on {len(train_data)} samples...\")\nprint(\"=\" * 80)\n\nfor idx, sample in enumerate(tqdm(train_data, desc=\"Evaluating\")):\n    qid = sample['qid']\n    question = sample['question']\n    relevant_laws = sample['relevant_laws']  # Ground truth\n    \n    # BM25 retrieval\n    try:\n        bm25_results = bm25_retriever.retrieve(question, top_k=TOP_K)\n        bm25_predicted = [str(aid) for aid, _ in bm25_results]\n    except Exception as e:\n        print(f\"Error in BM25 retrieval for sample {qid}: {e}\")\n        bm25_predicted = []\n    \n    # Dense retrieval\n    try:\n        dense_results = dense_retriever.retrieve(question, top_k=TOP_K)\n        dense_predicted = [str(aid) for aid, _ in dense_results]\n    except Exception as e:\n        print(f\"Error in Dense retrieval for sample {qid}: {e}\")\n        dense_predicted = []\n    \n    # Ensemble retrieval\n    try:\n        ensemble_results = ensemble_retriever.retrieve(question, top_k=TOP_K)\n        ensemble_predicted = [str(aid) for aid, _ in ensemble_results]\n    except Exception as e:\n        print(f\"Error in Ensemble retrieval for sample {qid}: {e}\")\n        ensemble_predicted = []\n    \n    # Calculate metrics\n    results['bm25']['precision'].append(\n        calculate_precision_at_k(bm25_predicted, relevant_laws, TOP_K)\n    )\n    results['bm25']['recall'].append(\n        calculate_recall_at_k(bm25_predicted, relevant_laws, TOP_K)\n    )\n    \n    results['dense']['precision'].append(\n        calculate_precision_at_k(dense_predicted, relevant_laws, TOP_K)\n    )\n    results['dense']['recall'].append(\n        calculate_recall_at_k(dense_predicted, relevant_laws, TOP_K)\n    )\n    \n    results['ensemble']['precision'].append(\n        calculate_precision_at_k(ensemble_predicted, relevant_laws, TOP_K)\n    )\n    results['ensemble']['recall'].append(\n        calculate_recall_at_k(ensemble_predicted, relevant_laws, TOP_K)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:22:04.959729Z","iopub.execute_input":"2025-12-04T15:22:04.960017Z","iopub.status.idle":"2025-12-04T15:37:35.914778Z","shell.execute_reply.started":"2025-12-04T15:22:04.959992Z","shell.execute_reply":"2025-12-04T15:37:35.913895Z"}},"outputs":[{"name":"stdout","text":"Evaluating on 2190 samples...\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 2190/2190 [15:30<00:00,  2.35it/s]\n","output_type":"stream"}],"execution_count":8},{"id":"28f7a6c1","cell_type":"code","source":"# Calculate average metrics\nsummary = {}\nfor method in ['bm25', 'dense', 'ensemble']:\n    summary[method] = {\n        'precision': np.mean(results[method]['precision']),\n        'recall': np.mean(results[method]['recall'])\n    }\n\n# Print results in table format\nprint(\"=\" * 80)\nprint(\"Table: Candidate retrieval performance on the VLSP 2025 DRiLL training set\")\nprint(\"=\" * 80)\nprint(f\"\\n{'Method':<20} {'P@500':<15} {'R@500':<15}\")\nprint(\"-\" * 80)\n\nmethod_names = {\n    'bm25': 'BM25',\n    'dense': 'Dense retrieval',\n    'ensemble': 'Hybrid search'\n}\n\nfor method in ['bm25', 'dense', 'ensemble']:\n    method_name = method_names[method]\n    p_at_100 = summary[method]['precision']\n    r_at_100 = summary[method]['recall']\n    print(f\"{method_name:<20} {p_at_100:<15.4f} {r_at_100:<15.4f}\")\n\nprint(\"=\" * 80)\nprint(f\"\\nTotal samples evaluated: {len(train_data)}\")\nprint(f\"Top-k: {TOP_K}\")\nprint(f\"Ensemble weights: BM25={BM25_WEIGHT}, Dense={DENSE_WEIGHT}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:37:36.293338Z","iopub.execute_input":"2025-12-04T15:37:36.293608Z","iopub.status.idle":"2025-12-04T15:37:36.302652Z","shell.execute_reply.started":"2025-12-04T15:37:36.293589Z","shell.execute_reply":"2025-12-04T15:37:36.301909Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nTable: Candidate retrieval performance on the VLSP 2025 DRiLL training set\n================================================================================\n\nMethod               P@500           R@500          \n--------------------------------------------------------------------------------\nBM25                 0.0039          0.8927         \nDense retrieval      0.0050          0.9701         \nHybrid search        0.0043          0.9764         \n================================================================================\n\nTotal samples evaluated: 2190\nTop-k: 300\nEnsemble weights: BM25=0.3, Dense=0.7\n","output_type":"stream"}],"execution_count":12},{"id":"d4f2c1ef","cell_type":"markdown","source":"## Save Results","metadata":{}},{"id":"9cfb8bdc","cell_type":"code","source":"# Save results to JSON\noutput_file = \"eval_stage1_results.json\"\noutput_data = {\n    'config': {\n        'top_k': TOP_K,\n        'num_samples': len(train_data),\n        'ensemble_weights': {'bm25': BM25_WEIGHT, 'dense': DENSE_WEIGHT}\n    },\n    'summary': summary,\n    'detailed_results': {\n        method: {\n            'precision': [float(x) for x in results[method]['precision']],\n            'recall': [float(x) for x in results[method]['recall']]\n        }\n        for method in ['bm25', 'dense', 'ensemble']\n    }\n}\n\nwith open(output_file, 'w', encoding='utf-8') as f:\n    json.dump(output_data, f, indent=2, ensure_ascii=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T15:37:52.132147Z","iopub.execute_input":"2025-12-04T15:37:52.132852Z","iopub.status.idle":"2025-12-04T15:37:52.152796Z","shell.execute_reply.started":"2025-12-04T15:37:52.132829Z","shell.execute_reply":"2025-12-04T15:37:52.152167Z"}},"outputs":[],"execution_count":13},{"id":"38d3cd27-d1ef-4a4c-84b6-1e49f3d7260e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}